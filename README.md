# Fusion Ledgers
EPIC Knowledge Society is building a Decentralised Data Fusion Ledger leveraging the power of cutting edge cryptographic primitives such as ZK SNARKS, Zokrates, Pendersen Commitments, Random Oracles, and Distributed Data Structures such as Direct Acyclic Graphs, Merkle Trees and JSON Schema. The fusion ledger is currently deployed using Ethereum and IPFS. We are planning the next iteration in Algorand and Aeternity. We will also upgrade the cryptographic primitives using ZK STARKS, Homomorphic Commitments, Interactive Oracle Proofs and Verifiable Random Functions. The fusion ledger is completely open source and currently in the prototyping phase. If anyone of you would like to contribute to the design and development of fusion ledger, please contact us at the email address - epicknowledgesociety@gmail.com

# Feature Summary 

Integrating a State Machine based Workflow into IPFS

Collecting Data Streams from Telemetry Data

Collecting Data Streams from Satellite Signals

Converting Data Streams into Graphs

Converting Graphs into Directed Acyclic Graphs

# Data Pipeine

 We will be processing data streams from sensors, actuators, maps, cameras, satellites etc. The standardised and normalised data streams will be processed using state machines and graphs. Currently our Data Engineering team is building streaming data processing pipelines on Apache Flink. In this pipeline you can find data fusion algorithms. We will do advanced state computations on Apache Flink and generate Fusion Graphs. 
 
# Offchain Computations

Fusion Graphs will be transfomed into verifiable graphs through IPFS. These graphs will be verified using authenticated graph feature in IPFS. Zero Knowledge Proofs and Pendersen Commitments are generates from Authenticated Graphs.IPFS stores Authenticated Graphs as Directed Acyclic Graphs of Merkle Trees. Proofs and commitments will be linked to DAGs and Merkle Trees Homomorphically. These Proofs and Commitments will be verified by Verifiable Random Functions. Zero Knowledge proofs and Pendersen commitments will be referred by Layer 2 Random Oracles based Asynchronous Consensus Algorithms. 

# Onchain Computations
The proofs and commitments will be verified by Data Verifiers through various Stake and Slash Proofs and Shared to Data Consumers who are authenticated and authorised through Multi Signature Wallets. 

# Ledger Users

There will be three set of users. Data Providers, Data Consumers and Data Verifiers.

# Implementation Roadmap

Schema Verification Tokens

Schema Verification Incentives

Schema Generation Tokens

Schema Generation Rewards

Schema Security Oracles

Tokens based on Workflows

Identities based on Activities

Proofs based on Interactions

Commitments and Proofs

Apriori Commitments

Apriori Proofs

Commitments prior to Proofs

Multi Signature Wallets

Winternitz One Time Signatures

Merkle Tree Signatures

Lamport Signatures

Contracts, Oracles and Data Sources

De-Identification of Data in Graphs

Anonymisation of Data through Proofs

State Transitions through Commitments

Turing Machine as a Polynomial

Zero Knowledge Proofs on a Turing Machine

Zero Knowledge Proofs on a Directed Acyclic Graph

Shortest Path of a Directed Acyclic Graph

Longest Path of a Directed Acyclic Graph

Graph Embedding in a Pendersen Commitment

Graph Embedding in a Zero Knowledge Proof
